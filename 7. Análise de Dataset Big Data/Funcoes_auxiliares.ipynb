{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0da4bd42-827c-41cc-8470-247c5454b74c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Função para carregamento da tabela (por quarters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d1d2bb9-d77c-40a0-9fae-c767a5a3f8fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def obter_tabela(tabela, trimestres):\n",
    "    list_df=[]\n",
    "    for trimestre in trimestres:\n",
    "        ano = trimestre[:4]\n",
    "        quarter = trimestre[-1]\n",
    "        path = f'/FileStore/faers-downloaded/faers_ascii_{trimestre}/ASCII/{tabela}{ano[-2:]}Q{quarter}.txt'\n",
    "        try:\n",
    "            df = spark.read.csv(path, sep='$', header=True, inferSchema=True)\n",
    "            list_df.append(df)\n",
    "            print(f\"Arquivo carregado com sucesso: {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar {path}: {str(e)}\")\n",
    "    if list_df:\n",
    "        df_all = list_df[0]\n",
    "        for df in list_df[1:]:\n",
    "            df_all = df_all.unionAll(df)\n",
    "        print(\"Todos os dataframes foram unidos com sucesso.\")\n",
    "        print(f\"Número total de linhas: {df_all.count()}\")\n",
    "    else:\n",
    "        print(\"Nenhum arquivo foi carregado com sucesso.\")\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0b319f5-a111-4ae9-a67f-2b6d6b3c22b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Função para transformar campos de datas de int para datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4910cc82-69c4-4077-be3f-d73be32f444f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def convert_date(df,date_col,dest_col):\n",
    "  # Suponha que o nome da sua coluna seja 'data_numero'\n",
    "  df = df.withColumn(\"data_string\", col(date_col).cast(\"string\"))\n",
    "\n",
    "  df = df.withColumn(dest_col, \n",
    "      when(length(col(\"data_string\")) == 8, to_date(col(\"data_string\"), \"yyyyMMdd\"))\n",
    "      .when(length(col(\"data_string\")) == 6, to_date(expr(\"concat(data_string, '01')\"), \"yyyyMMdd\"))\n",
    "      .when(length(col(\"data_string\")) == 4, to_date(expr(\"concat(data_string, '0101')\"), \"yyyyMMdd\"))\n",
    "  )\n",
    "  return df.drop(col(\"data_string\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2559b481-1b92-4756-95e3-12702c86295a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Função que restaura os metadados de um schema original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "194c40a0-d114-47ff-9ce4-9d78fff795d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def restore_metadata(schema,df):\n",
    "    for field in schema.fields:\n",
    "        if field.name in df.columns:\n",
    "            df = df.withMetadata(field.name, field.metadata)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "870c1812-b539-4bdb-913c-b6431164c1bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Função que carrega parquets finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91838886-80e1-4569-89e3-ba9e97ee4cd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[occr_country: string, occr_country_text: string, reporter_country: string, reporter_country_text: string, occp_cod: string, occp_txt: string, rept_cod: string, rept_typ_txt: string, primaryid: bigint, caseid: bigint, caseversion: int, event_dt: date, mfr_dt: date, init_fda_dt: date, fda_dt: date, auth_num: string, mfr_num: string, mfr_sndr: string, lit_ref: string, age: int, age_cod: string, age_grp: string, sex: string, e_sub: boolean, wt: double, wt_cod: string, rept_dt: date, to_mfr: boolean, folup_rpt: boolean, age_in_years: double, wt_in_kg: double]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_parquet(tabela):\n",
    "    path = f'dbfs:/FileStore/FAERS-grupo-4/{tabela}_final'\n",
    "    return spark.read.parquet(path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Funcoes_auxiliares",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
