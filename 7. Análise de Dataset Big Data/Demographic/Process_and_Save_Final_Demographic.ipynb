{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "290351a8-f45d-410f-a79c-ea3668e9efe7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Notebook 3: Funções de Transformação e Limpeza de Dados\n",
    "\n",
    "## Introdução\n",
    "Neste notebook, iremos implementar as transformações e limpar os dados da tabela 'Demographic' do conjunto de dados FAERS, com base na análise exploratória realizada no notebook anterior (Exploratory_Data_Analysis_Demographic). \n",
    "\n",
    "## Estrutura do notebook\n",
    "- Importação de Bibliotecas\n",
    "- Carregamento dos Dados (Parquet Raw) usando o Schema definido \n",
    "- Aplicar apenas as Transformações necessárias\n",
    "- Salvar **Parquet Final** com os Dados Limpos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2f90a46-ea2f-435e-9741-a2f0019cc3ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, LongType, DoubleType\n",
    "from pyspark.sql.functions import col, when, length, to_date, expr, round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65f7cd06-d6e0-425e-850a-7b3d9edcde24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../Funcoes_auxiliares\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2f35ec4-be5c-44f9-8958-142975c96f92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Carregar dados do Parquet raw\n",
    "schema_demo = StructType ([\n",
    "  StructField('primaryid',LongType(),False,{'description':'Unique number for identifying a FAERS report'}),\n",
    "  StructField('caseid',LongType(),False,{'description':'Number for identifying a FAERS case.'}),\n",
    "  StructField('caseversion',IntegerType(),False,{'description':'Safety Report Version Number'}),\n",
    "  StructField('i_f_code',StringType(),False,{'description':'Code for initial or follow-up status of report, as reported by manufacturer.'}),\n",
    "  StructField('event_dt',IntegerType(),True,{'description':'Date the adverse event occurred or began'}),\n",
    "  StructField('mfr_dt',IntegerType(),True,{'description':'Date manufacturer first received initial information'}),\n",
    "  StructField('init_fda_dt',IntegerType(),True,{'description':'Date FDA received first version (Initial) of Case'}),\n",
    "  StructField('fda_dt',IntegerType(),True,{'description':'Date FDA received Case'}),\n",
    "  StructField('rept_cod',StringType(),False,{'description':'Code for the type of report submitted'}), \n",
    "  StructField('auth_num',StringType(),True,{'description':'Regulatory Authority’s case report number'}),\n",
    "  StructField('mfr_num',StringType(),True,{'description':'Manufacturer’s unique report identifier'}),\n",
    "  StructField('mfr_sndr',StringType(),False,{'description':'Coded name of manufacturer sending report'}),\n",
    "  StructField('lit_ref',StringType(),True,{'description':'Literature Reference information'}),\n",
    "  StructField('age',IntegerType(),True,{'description':'Numeric value of patient’s age at event.'}),\n",
    "  StructField('age_cod',StringType(),True,{'description':'Unit abbreviation for patient’s age'}),\n",
    "  StructField('age_grp',StringType(),True,{'description':'Patient Age Group code'}),\n",
    "  StructField('sex',StringType(),True,{'description':'Code for patient’s sex'}),\n",
    "  StructField('e_sub',StringType(),False,{'description':'Whether this report was submitted under the electronic submissions procedure for manufacturers'}),\n",
    "  StructField('wt',DoubleType(),True,{'description':'Numeric value of patient’s weight.'}),\n",
    "  StructField('wt_cod',StringType(),True,{'description':'Unit abbreviation for patient’s weight'}),\n",
    "  StructField('rept_dt',IntegerType(),True,{'description':'Date report was sent'}),\n",
    "  StructField('to_mfr',StringType(),True,{'description':'Whether voluntary reporter also notified manufacturer'}),\n",
    "  StructField('occp_cod',StringType(),True,{'description':'Abbreviation for the reporter’s type of occupation in the latest version of a case.'}),\n",
    "  StructField('reporter_country',StringType(),True, {'description': \"Reporter Country Code\"}),\n",
    "  StructField('occr_country',StringType(),True,{'description':'The country where the event occurred.'})\n",
    "  ]\n",
    ")\n",
    "df_demo = spark.read.format('parquet').schema(schema_demo).load('dbfs:/FileStore/FAERS-grupo-4/demo_raw')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "825d0142-edbe-44b2-910a-7bea1c71cd75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#i_f_code para bool\n",
    "df_demo = df_demo.withColumn(\"folup_rpt\", when(df_demo['i_f_code'] == 'F', True).otherwise(False))\n",
    "df_demo=df_demo.drop(df_demo['i_f_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79efa9ee-763e-46d1-b7a3-d2b3fda7782c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# aplicar transformação para data de todas as colunas '_dt' através da função convert_date.  \n",
    "colunas_dt = [x for x in df_demo.columns if x.endswith('_dt')]\n",
    "for coluna in colunas_dt:\n",
    "    df_demo = convert_date(df_demo,coluna,coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eca6651c-35d6-48d6-ab36-c9c9656c9319",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Fazer mapeamento da coluna 'rept_cod' para 'rept_typ_txt'\n",
    "mapping_data = [\n",
    "    (\"EXP\", \"Expedited (15-Day)\"),\n",
    "    (\"PER\", \"Periodic (Non-Expedited)\"),\n",
    "    (\"DIR\", \"Direct\"),\n",
    "    (\"5DAY\", \"5-Day\"),\n",
    "    (\"30DAY\", \"30-Day\")\n",
    "]\n",
    "mapping_columns = [\"rept_cod\", \"rept_typ_txt\"]\n",
    "df_mapping = spark.createDataFrame(mapping_data, mapping_columns)\n",
    "\n",
    "# Join entre df_rept_cod e o DataFrame de mapeamento\n",
    "df_demo= df_mapping.join(df_demo, on=\"rept_cod\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19c940e1-f367-4087-beb2-4b702c6d9cb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#corrgir nulls na coluna age_cod  \n",
    "df_demo = df_demo.withColumn(\n",
    "    \"age_cod\",\n",
    "    when(\n",
    "        (col(\"age_grp\") == \"A\") & (col(\"age_cod\").isNull()) & (col(\"age\").isNotNull()) & (col(\"age\")>18) & (col(\"age\")<150),\n",
    "        \"YR\"\n",
    "    )\n",
    "    .when(\n",
    "        (col(\"age_grp\") == \"E\") & (col(\"age_cod\").isNull()) & (col(\"age\").isNotNull()) & (col(\"age\")>18) & (col(\"age\")<150),\n",
    "        \"YR\"\n",
    "    )\n",
    "    .when( col(\"age_cod\").isNotNull(), \n",
    "        col(\"age_cod\")\n",
    "\n",
    "    )  # Defina o valor padrão para outras condições\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f14352cf-599c-4924-af7a-3675cddc5f66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Normalizar 'age' em 'years'\n",
    "df_demo = df_demo.withColumn(\n",
    "    \"age_in_years\",\n",
    "      when(col(\"age_cod\") == \"MON\", round(col(\"age\") / 12, 2))\n",
    "      .when(col(\"age_cod\") == \"HR\", round(col(\"age\")/(24*365) , 2))\n",
    "      .when(col(\"age_cod\") == \"DY\", round(col(\"age\")/365 , 2))\n",
    "      .when(col(\"age_cod\") == \"DEC\", round(col(\"age\")*10 , 2))\n",
    "      .when(col(\"age_cod\") == \"WK\", round(col(\"age\")/52 , 2))\n",
    "      .when(col(\"age_cod\") == \"YR\", col(\"age\")).otherwise(None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55789ccc-be93-463b-a35a-d57615ae03ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#corrigir nulls na coluna age_grp\n",
    "df_demo = df_demo.withColumn(\"age_grp\",\n",
    "   when(col(\"age_grp\").isNotNull(),col(\"age_grp\")) \n",
    "    .when(col(\"age_in_years\") < (28.0/365), \"N\")\n",
    "    .when((col(\"age_in_years\") >= (28.0/365)) & (col(\"age_in_years\") < 2), \"I\")\n",
    "    .when((col(\"age_in_years\") >= 2) & (col(\"age_in_years\") < 12), \"C\")\n",
    "    .when((col(\"age_in_years\") >= 12) & (col(\"age_in_years\") < 22), \"T\")\n",
    "    .when((col(\"age_in_years\") >= 22) & (col(\"age_in_years\") < 65), \"A\")\n",
    "    .when(col(\"age_in_years\") >= 65 , \"E\")\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "335c7343-de87-4d96-bb44-1b916ec7fedd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Fazer fill dos nulls do sex por UNK\n",
    "df_demo = df_demo.fillna({'sex':'UNK'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50947821-12fc-4a50-aede-89105216abe3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#fazer conversão para booleano da coluna e_sub\n",
    "df_demo = df_demo.withColumn(\"e_sub\",when(col(\"e_sub\")=='Y',True).otherwise(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "295b6c82-f82f-444d-a9ec-9d78b6da4fca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#fazer a substituição de UNK por null na coluna wt_cod\n",
    "df_demo = df_demo.withColumn(\"wt_cod\", when(col(\"wt_cod\") == \"UNK\", None).otherwise(col(\"wt_cod\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef3b36b3-4e9f-41d3-9399-16e0b4ab54d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#criar coluna wt_in_kg\n",
    "df_demo = df_demo.withColumn(\n",
    "    \"wt_in_kg\",\n",
    "      when(col(\"wt_cod\") == \"KG\", round(col(\"wt\"), 3))\n",
    "      .when(col(\"wt_cod\") == \"LBS\", round(col(\"wt\")/2.2046 , 3))\n",
    "      .when(col(\"wt_cod\") == \"GMS\", round(col(\"wt\")/1000 , 3)).otherwise(None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4c42c26-7f9e-4aa6-ae02-45a201b63418",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#fazer a conversão da coluna to_mfr para booleano substituindo UNK por nulls\n",
    "df_demo = df_demo.withColumn(\"to_mfr\",when(col(\"to_mfr\")=='Y',True).when(col(\"to_mfr\")=='N',False).otherwise(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de942cf3-9df4-40b9-aef2-89d397722205",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#fazer a substituição de UNK por null na coluna occp_cod\n",
    "df_demo = df_demo.withColumn(\"occp_cod\", when(col(\"occp_cod\") == \"UNK\", None).otherwise(col(\"occp_cod\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76e668cf-9d29-4d20-abed-1abf50e8193d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#criar a coluna occp_txt\n",
    "mapping_data = [\n",
    "    (\"MD\", \"Physician\"),\n",
    "    (\"PH\", \"Pharmacist\"),\n",
    "    (\"OT\", \"Other health-professional\"),\n",
    "    (\"LW\", \"Lawyer\"),\n",
    "    (\"CN\", \"Consumer\")\n",
    "]\n",
    "mapping_columns = [\"occp_cod\", \"occp_txt\"]\n",
    "df_mapping = spark.createDataFrame(mapping_data, mapping_columns)\n",
    "\n",
    "# Join entre df_rept_cod e o DataFrame de mapeamento\n",
    "df_demo = df_demo.join(df_mapping, on=\"occp_cod\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d54a4ee3-b167-4d9e-9b08-71d5c0b6eb23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#substituir UNKs e nulls por Country not specified\n",
    "df_demo = df_demo.withColumn(\"reporter_country\", when(length(col(\"reporter_country\")) != 2, 'Country not specified').otherwise(col(\"reporter_country\"))).fillna({'reporter_country': 'Country not specified'})\n",
    "df_demo = df_demo.withColumn(\"occr_country\", when(length(col(\"occr_country\")) != 2, 'Country not specified').otherwise(col(\"occr_country\"))).fillna({'occr_country': 'Country not specified'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5729eceb-e3c6-4fd4-aec0-3b6c5f28b4df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#criar df_countries\n",
    "df_countries = spark.read.csv(\"dbfs:/FileStore/NCIt_GENC_Terminology.txt\", header=True, inferSchema=True, sep='\\t').select(['GENC 2 Letter Code','GENC Name (FDA Standard)']).dropna().withColumnsRenamed({'GENC 2 Letter Code':'reporter_country','GENC Name (FDA Standard)':'reporter_country_text'})\n",
    "new_rows = [('Country not specified', 'Country not specified')]\n",
    "new_df = spark.createDataFrame(new_rows, ['reporter_country','reporter_country_text'])\n",
    "df_countries = df_countries.union(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43899095-8ab8-4600-a5fb-3a3d28d13dbd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Criar coluna reporter_country_text\n",
    "df_demo = df_demo.join(df_countries, on=\"reporter_country\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "870e53e8-63c7-423d-8ae5-8417145d4de6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Alterar titulos df_countries para occr_country e criar occr_country_text\n",
    "df_demo = df_demo.join(df_countries.withColumnsRenamed({'reporter_country':'occr_country','reporter_country_text':'occr_country_text'}), on=\"occr_country\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55ba3300-2fe3-4e72-9b99-ad7176b5108a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Restaurar metadados\n",
    "df_demo = restore_metadata(schema_demo,df_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d9742ef-a8dd-4281-a8a1-91cc3537e4c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# salvar parquet final\n",
    "df_demo.write.mode('overwrite').parquet(\"dbfs:/FileStore/FAERS-grupo-4/demo_final\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Process_and_Save_Final_Demographic",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
